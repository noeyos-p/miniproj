import { useState, useRef, useCallback, useEffect } from 'react';
import './VisionAssistant.css';

// Web Speech API íƒ€ì… ì •ì˜
interface SpeechRecognitionEvent extends Event {
  results: SpeechRecognitionResultList;
}

interface SpeechRecognitionErrorEvent extends Event {
  error: string;
}

interface SpeechRecognition extends EventTarget {
  lang: string;
  continuous: boolean;
  interimResults: boolean;
  start(): void;
  stop(): void;
  abort(): void;
  onstart: ((this: SpeechRecognition, ev: Event) => void) | null;
  onresult: ((this: SpeechRecognition, ev: SpeechRecognitionEvent) => void) | null;
  onerror: ((this: SpeechRecognition, ev: SpeechRecognitionErrorEvent) => void) | null;
  onend: ((this: SpeechRecognition, ev: Event) => void) | null;
}

declare global {
  interface Window {
    SpeechRecognition: new () => SpeechRecognition;
    webkitSpeechRecognition: new () => SpeechRecognition;
  }
}

// í”„ë¡œë•ì…˜: ë¹ˆ ë¬¸ìì—´(ìƒëŒ€ ê²½ë¡œ), ê°œë°œ: localhost:8000
// const API_URL = import.meta.env.VITE_API_URL || (import.meta.env.DEV ? 'http://localhost:8000' : '');
const API_URL = import.meta.env.VITE_API_URL || '';

interface ConversationItem {
  type: 'question' | 'answer';
  text: string;
  timestamp: Date;
}
const USAGE_INSTRUCTIONS = `
ì•± ì‚¬ìš© ë°©ë²•ì„ ì•ˆë‚´í•´ ë“œë¦½ë‹ˆë‹¤.
ì²«ì§¸, í™”ë©´ì˜ ë²„íŠ¼ì„ í•œ ë²ˆ ëˆ„ë¥´ë©´ ì–´ë–¤ ë²„íŠ¼ì¸ì§€ ìŒì„±ìœ¼ë¡œ ì•Œë ¤ì¤ë‹ˆë‹¤.
ë‘˜ì§¸, ì„ íƒí•œ ê¸°ëŠ¥ì„ ì‹¤í–‰í•˜ë ¤ë©´ í™”ë©´ì˜ ì•„ë¬´ ê³³ì´ë‚˜ ë‘ ë²ˆ ë¹ ë¥´ê²Œ ë‘ë“œë¦¬ì„¸ìš”.
ì…‹ì§¸, ì¹´ë©”ë¼ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì‚¬ì§„ì„ ì°ê±°ë‚˜, ì´ë¯¸ì§€ ë° ì˜ìƒì„ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ë„·ì§¸, ì§ˆë¬¸í•˜ê¸° ë²„íŠ¼ì„ ëˆ„ë¥´ê³  ë§ˆì´í¬ì— ëŒ€ê³  ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”.
ì„¤ëª…ì„ ë‹¤ì‹œ ë“¤ìœ¼ë ¤ë©´ ì‚¬ìš©ë²• ë“£ê¸° ë²„íŠ¼ì„ ì„ íƒí•˜ê³  í™”ë©´ì„ ë‘ ë²ˆ ë‘ë“œë¦¬ì„¸ìš”.
`;

function App() {
  // ë¯¸ë””ì–´ ìƒíƒœ
  const [image, setImage] = useState<string | null>(null);
  const [video, setVideo] = useState<string | null>(null);
  const [mediaType, setMediaType] = useState<'image' | 'video'>('image');

  // UI ìƒíƒœ
  const [question, setQuestion] = useState('');
  const [conversation, setConversation] = useState<ConversationItem[]>([]);
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [streamingText, setStreamingText] = useState('');

  // ìŒì„± ìƒíƒœ (í•­ìƒ í™œì„±í™”)
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isListening, setIsListening] = useState(false);

  // ì ‘ê·¼ì„± ìƒíƒœ (ì„ íƒëœ ì•¡ì…˜)
  const pendingActionRef = useRef<(() => void) | null>(null);

  // ì¹´ë©”ë¼/ë…¹í™” ìƒíƒœ
  const [cameraActive, setCameraActive] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [recordingTime, setRecordingTime] = useState(0);
  const [videoDuration, setVideoDuration] = useState<number | null>(null);

  // Refs
  const fileInputRef = useRef<HTMLInputElement>(null);
  const videoFileInputRef = useRef<HTMLInputElement>(null);
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const questionInputRef = useRef<HTMLTextAreaElement>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const recordedChunksRef = useRef<Blob[]>([]);
  const conversationEndRef = useRef<HTMLDivElement>(null);
  const abortControllerRef = useRef<AbortController | null>(null);
  const recognitionRef = useRef<SpeechRecognition | null>(null);
  const recordingTimerRef = useRef<number | null>(null);
  const mimeTypeRef = useRef<string>('video/webm');
  const isCancelledRef = useRef<boolean>(false);

  // ìŠ¤í¬ë¡¤
  useEffect(() => {
    conversationEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [conversation, streamingText]);

  // TTS (í•­ìƒ í™œì„±í™”)
  const speak = useCallback((text: string) => {
    if (!('speechSynthesis' in window)) return;
    window.speechSynthesis.cancel();
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = 'ko-KR';
    utterance.rate = 0.9;
    utterance.onstart = () => setIsSpeaking(true);
    utterance.onend = () => setIsSpeaking(false);
    utterance.onerror = () => setIsSpeaking(false);
    window.speechSynthesis.speak(utterance);
  }, []);

  const stopSpeaking = useCallback(() => {
    window.speechSynthesis.cancel();
    setIsSpeaking(false);
  }, []);

  // ì ‘ê·¼ì„± ì„ íƒ í•¸ë“¤ëŸ¬ (í•­ìƒ ìŒì„± ì•ˆë‚´ í›„ ë”ë¸”í´ë¦­ìœ¼ë¡œ ì‹¤í–‰)
  const handleSelection = useCallback((label: string, action?: () => void) => {
    return (e?: React.SyntheticEvent) => {
      e?.preventDefault();
      e?.stopPropagation();

      speak(`${label} ì„ íƒë¨. ì‹¤í–‰í•˜ë ¤ë©´ í™”ë©´ì„ ë‘ ë²ˆ ë‘ë“œë¦¬ì„¸ìš”.`);
      pendingActionRef.current = action || null;
    };
  }, [speak]);

  // ì „ì—­ ë”ë¸” í´ë¦­/íƒ­ í•¸ë“¤ëŸ¬ (ì‹¤í–‰)
useEffect(() => {
  let lastTap = 0;

  const executeAction = () => {
    if (pendingActionRef.current) {
      pendingActionRef.current();
      pendingActionRef.current = null;
    }
  };

  // ë°ìŠ¤í¬í†±ìš© ë”ë¸”í´ë¦­
  const handleGlobalDoubleClick = () => {
    executeAction();
  };

  // ëª¨ë°”ì¼ìš© ë”ë¸”íƒ­
  const handleTouchEnd = (e: TouchEvent) => {
    const now = Date.now();
    const DOUBLE_TAP_DELAY = 300;

    if (now - lastTap < DOUBLE_TAP_DELAY) {
      e.preventDefault();
      executeAction();
      lastTap = 0; // ë¦¬ì…‹
    } else {
      lastTap = now;
    }
  };

  window.addEventListener('dblclick', handleGlobalDoubleClick);
  window.addEventListener('touchend', handleTouchEnd, { passive: false });

  return () => {
    window.removeEventListener('dblclick', handleGlobalDoubleClick);
    window.removeEventListener('touchend', handleTouchEnd);
  };
}, []);
  // ì…ë ¥ì°½ í¬ì»¤ìŠ¤ í•¸ë“¤ëŸ¬
  const handleInputFocus = useCallback(() => {
    speak('ì§ˆë¬¸ ì…ë ¥ì°½ì…ë‹ˆë‹¤. ê¶ê¸ˆí•œ ì ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.');
  }, [speak]);

  // STT ì´ˆê¸°í™”
  useEffect(() => {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (SpeechRecognition) {
      const recognition = new SpeechRecognition();
      recognition.lang = 'ko-KR';
      recognition.continuous = false;
      recognition.interimResults = true;

      recognition.onstart = () => {
        setIsListening(true);
        speak('ë“£ê³  ìˆìŠµë‹ˆë‹¤. ë§ì”€í•´ì£¼ì„¸ìš”.');
      };

      recognition.onresult = (event: SpeechRecognitionEvent) => {
        const transcript = Array.from(event.results).map(result => result[0].transcript).join('');
        setQuestion(transcript);
      };

      recognition.onerror = (event: SpeechRecognitionErrorEvent) => {
        console.error('STT Error:', event.error);
        setIsListening(false);
        if (event.error === 'not-allowed') {
          setError('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
          speak('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
        } else if (event.error !== 'no-speech') {
          speak('ìŒì„± ì¸ì‹ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
        }
      };

      recognition.onend = () => {
        setIsListening(false);
      };

      recognitionRef.current = recognition;
    }
    return () => { if (recognitionRef.current) recognitionRef.current.abort(); };
  }, [speak]);

  const toggleListening = useCallback(() => {
    if (!recognitionRef.current) {
      setError('ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €ì…ë‹ˆë‹¤.');
      speak('ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.');
      return;
    }
    if (isListening) {
      recognitionRef.current.stop();
      speak('ìŒì„± ì¸ì‹ì„ ì¤‘ì§€í•©ë‹ˆë‹¤.');
    } else {
      window.speechSynthesis.cancel();
      recognitionRef.current.start();
    }
  }, [isListening, speak]);

  const stopStreaming = useCallback(() => {
    if (abortControllerRef.current) {
      abortControllerRef.current.abort();
      abortControllerRef.current = null;
    }
  }, []);

  // ì¹´ë©”ë¼ ì‹œì‘
  const startCamera = useCallback(async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: 'environment' },
        audio: true,
      });
      streamRef.current = stream;
      setCameraActive(true);
    } catch (err) {
      console.error('Camera error:', err);
      setError('ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
      speak('ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
    }
  }, [speak]);

  useEffect(() => {
    if (cameraActive && videoRef.current && streamRef.current) {
      videoRef.current.srcObject = streamRef.current;
      videoRef.current.play().catch(console.error);
      speak('ì¹´ë©”ë¼ê°€ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.');
    }
  }, [cameraActive, speak]);

  const stopCamera = useCallback(() => {
    isCancelledRef.current = true;

    if (recordingTimerRef.current) {
      clearInterval(recordingTimerRef.current);
      recordingTimerRef.current = null;
    }
    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
      mediaRecorderRef.current.stop();
    }
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }
    if (videoRef.current) {
      videoRef.current.srcObject = null;
    }
    setCameraActive(false);
    setIsRecording(false);
    setRecordingTime(0);
  }, []);

  // ì‚¬ì§„ ì´¬ì˜
  const capturePhoto = useCallback(() => {
    if (!videoRef.current || !canvasRef.current) return;
    const video = videoRef.current;
    const canvas = canvasRef.current;
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    const ctx = canvas.getContext('2d');
    if (ctx) {
      ctx.drawImage(video, 0, 0);
      const imageData = canvas.toDataURL('image/jpeg', 0.8);
      setImage(imageData);
      setVideo(null);
      setMediaType('image');
      setConversation([]);
      stopCamera();
      speak('ì‚¬ì§„ì´ ì´¬ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.');
      setTimeout(() => questionInputRef.current?.focus(), 100);
    }
  }, [stopCamera, speak]);

  // ë…¹í™” ì¤‘ì§€
  const stopRecording = useCallback((): void => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
      mediaRecorderRef.current.stop();
    }

    if (recordingTimerRef.current) {
      clearInterval(recordingTimerRef.current);
      recordingTimerRef.current = null;
    }

    setIsRecording(false);
  }, []);

  // ë…¹í™” ì‹œì‘
  const startRecording = useCallback((): void => {
    if (!streamRef.current) return;

    try {
      const mediaRecorder = new MediaRecorder(streamRef.current);
      mimeTypeRef.current = mediaRecorder.mimeType;
      console.log('Recording with MIME type:', mimeTypeRef.current);

      recordedChunksRef.current = [];

      mediaRecorder.ondataavailable = (event: BlobEvent) => {
        if (event.data.size > 0) {
          recordedChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = () => {
        if (isCancelledRef.current) {
          console.log('Recording cancelled');
          return;
        }

        const blob = new Blob(recordedChunksRef.current, { type: mimeTypeRef.current });
        console.log('Created blob with type:', mimeTypeRef.current, 'size:', blob.size);

        const reader = new FileReader();

        reader.onloadend = () => {
          const base64 = reader.result as string;
          setVideo(base64);
          setImage(null);
          setMediaType('video');
          setConversation([]);
          stopCamera();
          speak('ì˜ìƒì´ ë…¹í™”ë˜ì—ˆìŠµë‹ˆë‹¤.');
          setTimeout(() => questionInputRef.current?.focus(), 100);
        };

        reader.readAsDataURL(blob);
      };

      isCancelledRef.current = false;
      mediaRecorderRef.current = mediaRecorder;
      mediaRecorder.start();

      setIsRecording(true);
      setRecordingTime(0);
      setVideoDuration(null);

      recordingTimerRef.current = window.setInterval(() => {
        setRecordingTime(prev => {
          if (prev >= 9) {
            stopRecording();
            setVideoDuration(10);
            return 10;
          }
          return prev + 1;
        });
      }, 1000);

      speak('ë…¹í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. 10ì´ˆ ë™ì•ˆ ë…¹í™”ë©ë‹ˆë‹¤.');
    } catch (err) {
      console.error('Recording error:', err);
      setError('ë…¹í™”ë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ë¸Œë¼ìš°ì € í˜¸í™˜ì„± ë˜ëŠ” ê¶Œí•œ ë¬¸ì œ)');
      setIsRecording(false);
    }
  }, [speak, stopCamera, stopRecording]);

  // ë…¹í™” í† ê¸€
  const toggleRecording = useCallback((): void => {
    if (isRecording) {
      stopRecording();
    } else {
      startRecording();
    }
  }, [isRecording, startRecording, stopRecording]);

  // ì´ë¯¸ì§€ íŒŒì¼ ì—…ë¡œë“œ
  const handleImageUpload = useCallback((event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (!file) return;
    if (!file.type.startsWith('image/')) {
      setError('ì´ë¯¸ì§€ íŒŒì¼ë§Œ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.');
      return;
    }
    const reader = new FileReader();
    reader.onload = (e) => {
      setImage(e.target?.result as string);
      setVideo(null);
      setMediaType('image');
      setConversation([]);
      setError(null);
      speak('ì´ë¯¸ì§€ê°€ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.');
      setTimeout(() => questionInputRef.current?.focus(), 100);
    };
    reader.readAsDataURL(file);
  }, [speak]);

  // ë¹„ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ
  const handleVideoUpload = useCallback((event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (!file) return;
    if (!file.type.startsWith('video/')) {
      setError('ë¹„ë””ì˜¤ íŒŒì¼ë§Œ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.');
      return;
    }
    if (file.size > 50 * 1024 * 1024) {
      setError('ë¹„ë””ì˜¤ íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤. (ìµœëŒ€ 50MB)');
      return;
    }
    const reader = new FileReader();
    reader.onload = (e) => {
      setVideo(e.target?.result as string);
      setImage(null);
      setMediaType('video');
      setConversation([]);
      setError(null);
      speak('ì˜ìƒì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.');
      setTimeout(() => questionInputRef.current?.focus(), 100);
    };
    reader.readAsDataURL(file);
  }, [speak]);

  // ì§ˆë¬¸ ì œì¶œ
  const handleSubmit = useCallback(async (e?: React.FormEvent) => {
    e?.preventDefault();

    if (!image && !video) {
      setError('ë¨¼ì € ì´ë¯¸ì§€ë‚˜ ì˜ìƒì„ ì¤€ë¹„í•´ì£¼ì„¸ìš”.');
      speak('ë¨¼ì € ì´ë¯¸ì§€ë‚˜ ì˜ìƒì„ ì¤€ë¹„í•´ì£¼ì„¸ìš”.');
      return;
    }
    if (!question.trim()) {
      setError('ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.');
      speak('ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.');
      return;
    }

    setIsLoading(true);
    setError(null);
    setStreamingText('');
    speak('ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤.');

    const formattedQuestion = question.trim() + (question.trim().endsWith('?') ? '' : '?');

    const newQuestion: ConversationItem = {
      type: 'question',
      text: formattedQuestion,
      timestamp: new Date(),
    };
    setConversation(prev => [...prev, newQuestion]);
    const currentQuestion = formattedQuestion;
    setQuestion('');

    abortControllerRef.current = new AbortController();

    try {
      // const endpoint = mediaType === 'video' ? '/api/ask-video-stream' : '/api/ask-stream';  // ê¸°ì¡´: ë…ë¦½ ì„œë²„ìš©
      const endpoint = mediaType === 'video' ? '/api/ask-video-stream' : '/api/ask-stream';  // ìˆ˜ì •: ë…ë¦½ ì„œë²„ëŠ” /mini2 prefix ì—†ìŒ
      const body = mediaType === 'video'
        ? { video_base64: video, question: currentQuestion, language: 'ko' }
        : { image_base64: image, question: currentQuestion, language: 'ko' };

      const response = await fetch(`${API_URL}${endpoint}`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(body),
        signal: abortControllerRef.current.signal,
      });

      if (!response.ok) throw new Error('ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜');

      const reader = response.body?.getReader();
      const decoder = new TextDecoder();
      let fullText = '';

      if (reader) {
        while (true) {
          const { done, value } = await reader.read();
          if (done) break;
          const chunk = decoder.decode(value, { stream: true });
          const lines = chunk.split('\n');
          for (const line of lines) {
            if (line.startsWith('data: ')) {
              const data = line.slice(6);
              if (data === '[DONE]') break;
              fullText += data;
              setStreamingText(fullText);
            }
          }
        }
      }

      const newAnswer: ConversationItem = {
        type: 'answer',
        text: fullText,
        timestamp: new Date(),
      };
      setConversation(prev => [...prev, newAnswer]);
      setStreamingText('');
      speak(fullText);

    } catch (err) {
      if ((err as Error).name !== 'AbortError') {
        console.error('API error:', err);
        setError('ì„œë²„ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
        speak('ì„œë²„ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
      }
    } finally {
      setIsLoading(false);
      abortControllerRef.current = null;
    }
  }, [image, video, mediaType, question, speak]);

  // ì „ì²´ ì„¤ëª…
  const handleDescribe = useCallback(async () => {
    if (!image && !video) {
      speak('ë¨¼ì € ì´ë¯¸ì§€ë‚˜ ì˜ìƒì„ ì¤€ë¹„í•´ì£¼ì„¸ìš”.');
      return;
    }

    setIsLoading(true);
    setStreamingText('');
    speak(mediaType === 'video' ? 'ì˜ìƒì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤.' : 'ì´ë¯¸ì§€ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤.');

    const describeQuestion: ConversationItem = {
      type: 'question',
      text: mediaType === 'video' ? 'ì´ ì˜ìƒì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.' : 'ì´ ì´ë¯¸ì§€ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.',
      timestamp: new Date(),
    };
    setConversation(prev => [...prev, describeQuestion]);

    abortControllerRef.current = new AbortController();

    try {
      // const endpoint = mediaType === 'video' ? '/api/describe-video-stream' : '/api/describe-stream';  // ê¸°ì¡´: ê²½ë¡œ ì˜¤ë¥˜
      const endpoint = mediaType === 'video' ? '/api/describe-video-stream' : '/api/describe-stream';  // ìˆ˜ì •: mini2 ë§ˆìš´íŠ¸ ê²½ë¡œ ë°˜ì˜
      const body = mediaType === 'video'
        ? { video_base64: video, question: '', language: 'ko' }
        : { image_base64: image, question: '', language: 'ko' };

      const response = await fetch(`${API_URL}${endpoint}`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(body),
        signal: abortControllerRef.current.signal,
      });

      const reader = response.body?.getReader();
      const decoder = new TextDecoder();
      let fullText = '';

      if (reader) {
        while (true) {
          const { done, value } = await reader.read();
          if (done) break;
          const chunk = decoder.decode(value, { stream: true });
          const lines = chunk.split('\n');
          for (const line of lines) {
            if (line.startsWith('data: ')) {
              const data = line.slice(6);
              if (data === '[DONE]') break;
              fullText += data;
              setStreamingText(fullText);
            }
          }
        }
      }

      const newAnswer: ConversationItem = {
        type: 'answer',
        text: fullText,
        timestamp: new Date(),
      };
      setConversation(prev => [...prev, newAnswer]);
      setStreamingText('');
      speak(fullText);

    } catch (err) {
      if ((err as Error).name !== 'AbortError') {
        speak('ì„¤ëª…ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
      }
    } finally {
      setIsLoading(false);
      abortControllerRef.current = null;
    }
  }, [image, video, mediaType, speak]);

  // ë¦¬ì…‹
  const handleReset = useCallback(() => {
    setImage(null);
    setVideo(null);
    setMediaType('image');
    setConversation([]);
    setQuestion('');
    setError(null);
    setStreamingText('');
    stopCamera();
    stopStreaming();
    speak('ìƒˆë¡œìš´ ì´ë¯¸ì§€ë‚˜ ì˜ìƒì„ ì¤€ë¹„í•´ì£¼ì„¸ìš”.');
  }, [stopCamera, stopStreaming, speak]);

  // ì •ë¦¬
  useEffect(() => {
    return () => {
      stopCamera();
      stopSpeaking();
      stopStreaming();
    };
  }, [stopCamera, stopSpeaking, stopStreaming]);

  // í‚¤ë³´ë“œ ë‹¨ì¶•í‚¤
  useEffect(() => {
    const handleKeyDown = (e: KeyboardEvent) => {
      if (e.ctrlKey && e.key === 'Enter') handleSubmit();
      if (e.key === 'Escape') { stopSpeaking(); stopStreaming(); }
    };
    window.addEventListener('keydown', handleKeyDown);
    return () => window.removeEventListener('keydown', handleKeyDown);
  }, [handleSubmit, stopSpeaking, stopStreaming]);

  return (
    <div className="app" role="application" aria-label="ì‹œê° ë„ìš°ë¯¸">
      <header className="header">
        <h1>ğŸ‘ï¸ ì‹œê° ë„ìš°ë¯¸</h1>
        <p className="subtitle">ì´ë¯¸ì§€ì™€ ì˜ìƒì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš”</p>

        {/* ìŒì„± ì¤‘ì§€ ë²„íŠ¼ë§Œ í‘œì‹œ */}
        {isSpeaking && (
          <div className="tts-controls">
            <button onClick={stopSpeaking} className="stop-speaking-btn">
              â¹ï¸ ìŒì„± ì¤‘ì§€
            </button>
          </div>
        )}

        <div className="help-area">
          <button
            onClick={handleSelection('ì•± ì‚¬ìš©ë²• ë“£ê¸°', () => speak(USAGE_INSTRUCTIONS))}
            className="btn btn-help"
          >
            â“ ì‚¬ìš©ë²• ë“£ê¸°
          </button>
        </div>
      </header>

      <main className="main-content">
        {/* ë¯¸ë””ì–´ ì˜ì—­ */}
        <section className="image-section" aria-label="ë¯¸ë””ì–´ ì˜ì—­">
          {!image && !video && !cameraActive && (
            <div className="image-input-area">
              <div className="media-buttons">
                <button onClick={handleSelection('ì¹´ë©”ë¼ ì‹¤í–‰', startCamera)} className="btn btn-primary btn-large">
                  ğŸ“· ì¹´ë©”ë¼
                </button>
                <button onClick={handleSelection('ì´ë¯¸ì§€ ì—…ë¡œë“œ', () => fileInputRef.current?.click())} className="btn btn-secondary btn-large">
                  ğŸ–¼ï¸ ì´ë¯¸ì§€
                </button>
                <button onClick={handleSelection('ì˜ìƒ ì—…ë¡œë“œ', () => videoFileInputRef.current?.click())} className="btn btn-secondary btn-large">
                  ğŸ¬ ì˜ìƒ
                </button>
              </div>

              <input
                ref={fileInputRef}
                type="file"
                accept="image/*"
                onChange={handleImageUpload}
                className="hidden-input"
              />
              <input
                ref={videoFileInputRef}
                type="file"
                accept="video/*"
                onChange={handleVideoUpload}
                className="hidden-input"
              />
            </div>
          )}

          {cameraActive && (
            <div className="camera-area">
              <video
                ref={videoRef}
                autoPlay
                playsInline
                muted
                className="camera-preview"
              />

              {isRecording && (
                <div className="recording-indicator">
                  ğŸ”´ ë…¹í™” ì¤‘ {recordingTime}ì´ˆ / 10ì´ˆ
                </div>
              )}

              <div className="camera-controls">
                <button
                  onClick={handleSelection('ì‚¬ì§„ ì´¬ì˜', capturePhoto)}
                  className="btn btn-capture"
                  disabled={isRecording}
                >
                  ğŸ“¸ ì‚¬ì§„
                </button>

                <button
                  type="button"
                  onClick={handleSelection(isRecording ? 'ë…¹í™” ì¤‘ì§€' : 'ë…¹í™” ì‹œì‘', toggleRecording)}
                  className={`btn ${isRecording ? 'btn-stop-record' : 'btn-record'}`}
                >
                  {isRecording ? 'â¹ï¸ ë…¹í™” ì¤‘ì§€' : 'ğŸ¬ ë…¹í™” ì‹œì‘'}
                </button>

                <button onClick={handleSelection('ì·¨ì†Œ', stopCamera)} className="btn btn-cancel">
                  âŒ ì·¨ì†Œ
                </button>
              </div>
            </div>
          )}

          {image && (
            <div className="image-preview-area">
              <div className="media-badge">ğŸ“· ì´ë¯¸ì§€</div>
              <img src={image} alt="ì—…ë¡œë“œëœ ì´ë¯¸ì§€" className="image-preview" />
              <div className="image-actions">
                <button onClick={handleSelection('ì „ì²´ ì„¤ëª… ìš”ì²­', handleDescribe)} className="btn btn-describe" disabled={isLoading}>
                  ğŸ“ ì „ì²´ ì„¤ëª…
                </button>
                <button onClick={handleSelection('ìƒˆë¡œ ì‹œì‘', handleReset)} className="btn btn-reset">
                  ğŸ”„ ìƒˆë¡œ ì‹œì‘
                </button>
              </div>
            </div>
          )}

          {video && (
            <div className="image-preview-area">
              <div className="media-badge">
                ğŸ¬ ì˜ìƒ {videoDuration ? `(${videoDuration}ì´ˆ)` : ''}
              </div>
              <video src={video} controls className="video-preview" />
              <div className="image-actions">
                <button onClick={handleSelection('ì „ì²´ ì„¤ëª… ìš”ì²­', handleDescribe)} className="btn btn-describe" disabled={isLoading}>
                  ğŸ“ ì „ì²´ ì„¤ëª…
                </button>
                <button onClick={handleSelection('ìƒˆë¡œ ì‹œì‘', handleReset)} className="btn btn-reset">
                  ğŸ”„ ìƒˆë¡œ ì‹œì‘
                </button>
              </div>
            </div>
          )}

          <canvas ref={canvasRef} className="hidden-canvas" />
        </section>

        {/* ëŒ€í™” ì˜ì—­ */}
        {(image || video) && (
          <section className="conversation-section" aria-label="ëŒ€í™” ì˜ì—­">
            <div className="conversation-list" role="log" aria-live="polite">
              {conversation.length === 0 && !streamingText && (
                <p className="empty-message">
                  {mediaType === 'video' ? 'ì˜ìƒ' : 'ì´ë¯¸ì§€'}ì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”.
                  <br />
                  ì˜ˆ: "ë­ê°€ ë³´ì—¬?", "ë­í•˜ê³  ìˆì–´?", "ë‚ ì”¨ê°€ ì–´ë•Œ?"
                </p>
              )}

              {conversation.map((item, index) => (
                <div key={index} className={`message ${item.type}`}>
                  <span className="message-icon">{item.type === 'question' ? 'â“' : 'ğŸ’¬'}</span>
                  <p className="message-text">{item.text}</p>
                  {item.type === 'answer' && (
                    <button onClick={handleSelection('ë‹µë³€ ë‹¤ì‹œ ë“£ê¸°', () => speak(item.text))} className="btn-speak">ğŸ”Š</button>
                  )}
                </div>
              ))}

              {streamingText && (
                <div className="message answer streaming">
                  <span className="message-icon">ğŸ’¬</span>
                  <p className="message-text">
                    {streamingText}<span className="cursor">â–Œ</span>
                  </p>
                </div>
              )}

              {isLoading && !streamingText && (
                <div className="message answer loading">
                  <span className="loading-spinner">â³</span>
                  <p>ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...</p>
                </div>
              )}

              <div ref={conversationEndRef} />
            </div>

            <form onSubmit={handleSubmit} className="question-form">
              <div className="input-wrapper">
                <textarea
                  ref={questionInputRef}
                  value={question}
                  onChange={(e) => setQuestion(e.target.value)}
                  onClick={handleInputFocus}
                  placeholder={`${mediaType === 'video' ? 'ì˜ìƒ' : 'ì´ë¯¸ì§€'}ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”...`}
                  className="question-input"
                  disabled={isLoading}
                  rows={2}
                />
                <button
                  type="button"
                  onClick={handleSelection(isListening ? 'ìŒì„± ì…ë ¥ ì¤‘ì§€' : 'ìŒì„± ì…ë ¥ ì‹œì‘', toggleListening)}
                  className={`btn btn-mic ${isListening ? 'listening' : ''}`}
                  disabled={isLoading}
                >
                  {isListening ? 'ğŸ”´' : 'ğŸ¤'}
                </button>
              </div>
              <div className="form-buttons">
                <button
                  type="button"
                  onClick={handleSelection('ì§ˆë¬¸ ë³´ë‚´ê¸°', handleSubmit)}
                  className="btn btn-send"
                  disabled={isLoading || !question.trim()}
                >
                  {isLoading ? 'â³' : 'ğŸ“¤'} ë³´ë‚´ê¸°
                </button>
                {isLoading && (
                  <button
                    type="button"
                    onClick={handleSelection('ë‹µë³€ ìƒì„± ì¤‘ì§€', stopStreaming)}
                    className="btn btn-stop"
                  >
                    â¹ï¸ ì¤‘ì§€
                  </button>
                )}
              </div>
            </form>
          </section>
        )}

        {error && (
          <div className="error-message" role="alert">
            âš ï¸ {error}
          </div>
        )}
      </main>

      <footer className="footer">
        <p>
          ğŸ¤ ë§ˆì´í¬ë¡œ ìŒì„± ì§ˆë¬¸ | ğŸ¬ 10ì´ˆ ì˜ìƒ ë…¹í™” | ë²„íŠ¼ ì„ íƒ í›„ í™”ë©´ ë”ë¸”íƒ­í•˜ì—¬ ì‹¤í–‰
        </p>
      </footer>
    </div>
  );
}

export default App;