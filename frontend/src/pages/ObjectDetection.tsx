import { useState, useRef, useCallback, useEffect } from 'react';
import './ObjectDetection.css';

// í”„ë¡œë•ì…˜: ë¹ˆ ë¬¸ìì—´(ìƒëŒ€ ê²½ë¡œ), ê°œë°œ: localhost:8000
// const API_URL = import.meta.env.VITE_API_URL || (import.meta.env.DEV ? 'http://localhost:8000' : '');
const API_URL = import.meta.env.VITE_API_URL || '';
const DOUBLE_CLICK_DELAY = 400;

const FEATURE_GUIDE = `
ì‹œê°ì¥ì• ì¸ ë³´ì¡° ì„œë¹„ìŠ¤ ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.

ì²«ì§¸, í™”ë©´ì„ ë‘ ë²ˆ í„°ì¹˜í•˜ë©´ ì‹œìŠ¤í…œì„ ì‹œì‘í•˜ê±°ë‚˜ ì •ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë‘˜ì§¸, í•˜ë‹¨ì˜ ë§ˆì´í¬ ë²„íŠ¼ì„ ë‘ ë²ˆ í„°ì¹˜í•˜ë©´ ìŒì„± ëª…ë ¹ì„ ë…¹ìŒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì‹œì‘í•´, ì •ì§€í•´, ë§í•´ì¤˜, ì¡°ìš©íˆí•´, ì¢…ë£Œí•´ ë“±ì˜ ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì…‹ì§¸, ìŒì†Œê±° ë²„íŠ¼ì„ ë‘ ë²ˆ í„°ì¹˜í•˜ë©´ í˜„ì¬ ì¬ìƒ ì¤‘ì¸ ìŒì„± ì•ˆë‚´ë¥¼ ì¤‘ì§€í•©ë‹ˆë‹¤.

ë„·ì§¸, ë§í•˜ê¸° ë²„íŠ¼ì„ ë‘ ë²ˆ í„°ì¹˜í•˜ë©´ í˜„ì¬ í™”ë©´ì˜ ìƒíƒœë¥¼ ìŒì„±ìœ¼ë¡œ ì•ˆë‚´í•©ë‹ˆë‹¤.

ë‹¤ì„¯ì§¸, ì¢…ë£Œ ë²„íŠ¼ì„ ë‘ ë²ˆ í„°ì¹˜í•˜ë©´ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.

ëª¨ë“  ë²„íŠ¼ì€ í•œ ë²ˆ í„°ì¹˜í•˜ë©´ í•´ë‹¹ ë²„íŠ¼ì˜ ì„¤ëª…ì„, ë‘ ë²ˆ í„°ì¹˜í•˜ë©´ ê¸°ëŠ¥ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
`;

interface Detection {
  box: [number, number, number, number];
  label: string;
  distance: number;
  roi: [number, number];
  track_id?: number;
  confidence?: number;
}

interface FrameSize {
  width: number;
  height: number;
}

function ObjectDetection() {
  // ìƒíƒœ
  const [isRunning, setIsRunning] = useState(false);
  const [statusText, setStatusText] = useState('í™”ë©´ì„ ë‘ ë²ˆ í„°ì¹˜í•˜ë©´ ì‹œì‘í•©ë‹ˆë‹¤.');
  const [statusColor, setStatusColor] = useState('white');
  const [isRecording, setIsRecording] = useState(false);

  // Refs
  const cameraPreviewRef = useRef<HTMLVideoElement>(null);
  const cameraCanvasRef = useRef<HTMLCanvasElement>(null);
  const overlayCanvasRef = useRef<HTMLCanvasElement>(null);

  const cameraStreamRef = useRef<MediaStream | null>(null);
  const frameIntervalRef = useRef<number | null>(null);
  const isProcessingRef = useRef(false);

  const clickTimerRef = useRef<number | null>(null);
  const screenClickTimerRef = useRef<number | null>(null);

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const audioStreamRef = useRef<MediaStream | null>(null);

  // TTS í•¨ìˆ˜
  const speak = useCallback((text: string) => {
    window.speechSynthesis.cancel();
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = 'ko-KR';
    utterance.rate = 1.0;
    window.speechSynthesis.speak(utterance);
  }, []);

  // ì˜¤ë²„ë ˆì´ì— ê°ì§€ ê²°ê³¼ ê·¸ë¦¬ê¸° (ë‹¤ì¤‘ ê°ì²´ ì§€ì›)
  const drawDetection = useCallback((detections: Detection[] | null, frameSize: FrameSize) => {
    const canvas = overlayCanvasRef.current;
    if (!canvas) {
      console.log('[Draw Debug] Canvas refê°€ ì—†ìŒ');
      return;
    }

    const ctx = canvas.getContext('2d');
    if (!ctx) {
      console.log('[Draw Debug] Contextë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ');
      return;
    }

    ctx.clearRect(0, 0, canvas.width, canvas.height);

    console.log('[Draw Debug] detections:', detections);
    console.log('[Draw Debug] frameSize:', frameSize);

    if (!detections || detections.length === 0) {
      console.log('[Draw Debug] ê°ì§€ëœ ê°ì²´ ì—†ìŒ');
      return;
    }

    console.log('[Draw Debug] ê°ì²´ ê·¸ë¦¬ê¸° ì‹œì‘ - ì´', detections.length, 'ê°œ');

    const scaleX = canvas.width / frameSize.width;
    const scaleY = canvas.height / frameSize.height;

    // ROI ê°€ì´ë“œ ë¼ì¸ (ì²« ë²ˆì§¸ ê°ì²´ì˜ ROI ì‚¬ìš©)
    const [roiLeft, roiRight] = detections[0].roi;
    ctx.strokeStyle = 'rgba(255, 0, 0, 0.5)';
    ctx.lineWidth = 2;
    ctx.beginPath();
    ctx.moveTo(roiLeft * scaleX, 0);
    ctx.lineTo(roiLeft * scaleX, canvas.height);
    ctx.moveTo(roiRight * scaleX, 0);
    ctx.lineTo(roiRight * scaleX, canvas.height);
    ctx.stroke();

    // ëª¨ë“  ê°ì§€ëœ ê°ì²´ ê·¸ë¦¬ê¸°
    detections.forEach((detection) => {
      const { box, label, distance, track_id } = detection;
      const [x1, y1, x2, y2] = box;

      // ê°ì§€ ë°•ìŠ¤
      ctx.strokeStyle = 'rgba(255, 0, 0, 1)';
      ctx.lineWidth = 3;
      ctx.strokeRect(x1 * scaleX, y1 * scaleY, (x2 - x1) * scaleX, (y2 - y1) * scaleY);

      // ë ˆì´ë¸” (Track ID í¬í•¨)
      ctx.fillStyle = 'rgba(255, 0, 0, 1)';
      ctx.font = '20px Arial';
      const labelText = track_id !== undefined && track_id !== null
        ? `ID:${track_id} ${label} ${distance}m`
        : `${label} ${distance}m`;
      ctx.fillText(labelText, x1 * scaleX, (y1 - 10) * scaleY);
    });
  }, []);

  // í”„ë ˆì„ ìº¡ì²˜ ë° ì „ì†¡
  const captureAndSendFrame = useCallback(async () => {
    if (!cameraStreamRef.current) return;
    if (isProcessingRef.current) return;

    const video = cameraPreviewRef.current;
    const canvas = cameraCanvasRef.current;
    if (!video || !canvas) return;

    const ctx = canvas.getContext('2d');
    if (!ctx) return;

    isProcessingRef.current = true;

    try {
      ctx.drawImage(video, 0, 0);

      const blob = await new Promise<Blob | null>((resolve) => {
        canvas.toBlob(resolve, 'image/jpeg', 0.7);
      });

      if (!blob) return;

      const formData = new FormData();
      formData.append('frame', blob, 'frame.jpg');

      // mini1 API ê²½ë¡œë¡œ ìˆ˜ì •
      const response = await fetch(`${API_URL}/mini1/process_frame`, {
        method: 'POST',
        body: formData,
      });

      if (response.ok) {
        const data = await response.json();
        // ë””ë²„ê¹…: ë°›ì€ ë°ì´í„° í™•ì¸
        console.log('[Frontend Debug] ë°›ì€ ë°ì´í„°:', data);
        console.log('[Frontend Debug] detection íƒ€ì…:', typeof data.detection, Array.isArray(data.detection));
        console.log('[Frontend Debug] detection ë‚´ìš©:', data.detection);

        drawDetection(data.detection, data.frame_size);

        if (data.speech && data.speech.length > 0) {
          speak(data.speech);
        }
      }
    } catch (error) {
      console.error('í”„ë ˆì„ ì „ì†¡ ì˜¤ë¥˜:', error);
    } finally {
      isProcessingRef.current = false;
    }
  }, [drawDetection, speak]);

  // ì¹´ë©”ë¼ ì‹œì‘
  const startCamera = useCallback(async (): Promise<boolean> => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: {
          facingMode: { ideal: 'environment' },
          width: { ideal: 640 },
          height: { ideal: 480 },
        },
      });

      cameraStreamRef.current = stream;

      if (cameraPreviewRef.current) {
        cameraPreviewRef.current.srcObject = stream;
      }

      return true;
    } catch (error) {
      console.error('ì¹´ë©”ë¼ ì ‘ê·¼ ì˜¤ë¥˜:', error);
      setStatusText('ì¹´ë©”ë¼ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”');
      return false;
    }
  }, []);

  // ì¹´ë©”ë¼ ì¤‘ì§€
  const stopCamera = useCallback(() => {
    if (frameIntervalRef.current) {
      clearInterval(frameIntervalRef.current);
      frameIntervalRef.current = null;
    }
    if (cameraStreamRef.current) {
      cameraStreamRef.current.getTracks().forEach((track) => track.stop());
      cameraStreamRef.current = null;
    }
    if (cameraPreviewRef.current) {
      cameraPreviewRef.current.srcObject = null;
    }
  }, []);

  // ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹œ ìº”ë²„ìŠ¤ í¬ê¸° ì„¤ì • ë° í”„ë ˆì„ ìº¡ì²˜ ì‹œì‘
  const handleVideoLoaded = useCallback(() => {
    const video = cameraPreviewRef.current;
    const canvas = cameraCanvasRef.current;
    const overlay = overlayCanvasRef.current;

    if (video && canvas && overlay) {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      overlay.width = video.videoWidth;
      overlay.height = video.videoHeight;

      // í”„ë ˆì„ ìº¡ì²˜ ì‹œì‘ (200ms = 5fps)
      frameIntervalRef.current = window.setInterval(captureAndSendFrame, 200);
    }
  }, [captureAndSendFrame]);

  // íŒŒì´í”„ë¼ì¸ í† ê¸€
  const togglePipeline = useCallback(async () => {
    const endpoint = isRunning ? `${API_URL}/mini1/stop` : `${API_URL}/mini1/start`;

    try {
      const response = await fetch(endpoint, { method: 'POST' });
      const data = await response.json();

      if (data.status === 'started' || data.status === 'already_running') {
        setIsRunning(true);
        setStatusText('ì‘ë™ ì¤‘... ë‘ ë²ˆ í„°ì¹˜í•˜ë©´ ì •ì§€í•©ë‹ˆë‹¤.');
        setStatusColor('#4CAF50');

        const cameraStarted = await startCamera();
        if (!cameraStarted) return;
      } else {
        setIsRunning(false);
        setStatusText('ì •ì§€ë¨. ë‘ ë²ˆ í„°ì¹˜í•˜ë©´ ì‹œì‘í•©ë‹ˆë‹¤.');
        setStatusColor('#FF5252');
        stopCamera();
      }
    } catch (error) {
      console.error('íŒŒì´í”„ë¼ì¸ í† ê¸€ ì˜¤ë¥˜:', error);
      speak('ì—°ê²° ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
    }
  }, [isRunning, startCamera, stopCamera, speak]);

  // í™”ë©´ í´ë¦­ ì²˜ë¦¬
  const handleScreenClick = useCallback(() => {
    if (screenClickTimerRef.current) {
      clearTimeout(screenClickTimerRef.current);
      screenClickTimerRef.current = null;
      window.speechSynthesis.cancel();
      togglePipeline();
    } else {
      screenClickTimerRef.current = window.setTimeout(() => {
        if (isRunning) {
          speak('í˜„ì¬ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤. ë‘ ë²ˆ í´ë¦­í•˜ë©´ ì •ì§€í•©ë‹ˆë‹¤.');
        } else {
          speak('í˜„ì¬ ì •ì§€ ìƒíƒœì…ë‹ˆë‹¤. ë‘ ë²ˆ í´ë¦­í•˜ë©´ ì‹œì‘í•©ë‹ˆë‹¤.');
        }
        screenClickTimerRef.current = null;
      }, DOUBLE_CLICK_DELAY);
    }
  }, [isRunning, togglePipeline, speak]);

  // ë²„íŠ¼ í´ë¦­ ì²˜ë¦¬ (í•œ ë²ˆ: ì„¤ëª…, ë‘ ë²ˆ: ê¸°ëŠ¥ ì‹¤í–‰)
  const handleButtonClick = useCallback(
    (e: React.MouseEvent, description: string, action?: () => void) => {
      e.stopPropagation();

      if (clickTimerRef.current) {
        clearTimeout(clickTimerRef.current);
        clickTimerRef.current = null;
        window.speechSynthesis.cancel();
        action?.();
      } else {
        clickTimerRef.current = window.setTimeout(() => {
          speak(description);
          clickTimerRef.current = null;
        }, DOUBLE_CLICK_DELAY);
      }
    },
    [speak]
  );

  // ëª…ë ¹ ì „ì†¡
  const sendCommand = useCallback(
    async (commandText: string) => {
      try {
        const response = await fetch(`${API_URL}/mini1/command`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ text: commandText }),
        });
        const data = await response.json();

        if (data.response) {
          speak(data.response);
        }
      } catch (error) {
        console.error('ëª…ë ¹ ì „ì†¡ ì˜¤ë¥˜:', error);
      }
    },
    [speak]
  );

  // ë§ˆì´í¬ ì´ˆê¸°í™”
  const initMicrophone = useCallback(async (): Promise<boolean> => {
    if (audioStreamRef.current?.active) return true;

    try {
      audioStreamRef.current = await navigator.mediaDevices.getUserMedia({ audio: true });
      return true;
    } catch (error) {
      console.error('ë§ˆì´í¬ ì ‘ê·¼ ì˜¤ë¥˜:', error);
      setStatusText('ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”');
      return false;
    }
  }, []);

  // ë…¹ìŒ ì‹œì‘
  const startRecording = useCallback(async () => {
    if (!audioStreamRef.current?.active) {
      setStatusText('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì„¸ìš”.');
      return;
    }

    try {
      const mediaRecorder = new MediaRecorder(audioStreamRef.current);
      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (e) => {
        audioChunksRef.current.push(e.data);
      };

      mediaRecorder.onstop = async () => {
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
        const formData = new FormData();
        formData.append('audio', audioBlob, 'recording.webm');

        try {
          setStatusText('ìŒì„± ì¸ì‹ ì¤‘...');
          const response = await fetch(`${API_URL}/mini1/voice`, {
            method: 'POST',
            body: formData,
          });
          const data = await response.json();
          setStatusText('ì¸ì‹: ' + data.text);

          if (data.response) {
            speak(data.response);
          }
        } catch (error) {
          console.error('ìŒì„± ì „ì†¡ ì˜¤ë¥˜:', error);
        }
      };

      mediaRecorderRef.current = mediaRecorder;
      mediaRecorder.start();
      setIsRecording(true);
    } catch (error) {
      console.error('ë…¹ìŒ ì‹œì‘ ì˜¤ë¥˜:', error);
    }
  }, [speak]);

  // ë…¹ìŒ ì¤‘ì§€
  const stopRecording = useCallback(() => {
    if (!mediaRecorderRef.current || mediaRecorderRef.current.state === 'inactive') return;

    mediaRecorderRef.current.stop();
    setIsRecording(false);
  }, []);

  // ë…¹ìŒ í† ê¸€
  const toggleRecording = useCallback(() => {
    if (isRecording) {
      stopRecording();
    } else {
      startRecording();
    }
  }, [isRecording, startRecording, stopRecording]);

  // í˜ì´ì§€ ë¡œë“œ ì‹œ ì´ˆê¸°í™”
  useEffect(() => {
    initMicrophone();

    const timer = setTimeout(() => {
      speak('ì‹œê°ì¥ì• ì¸ ë³´ì¡° ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. ë²„íŠ¼ì„ í•œ ë²ˆ í„°ì¹˜í•˜ë©´ ì„¤ëª…ì„, ë‘ ë²ˆ í„°ì¹˜í•˜ë©´ ê¸°ëŠ¥ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.');
    }, 1000);

    return () => {
      clearTimeout(timer);
      stopCamera();
    };
  }, [initMicrophone, speak, stopCamera]);

  return (
    <div className="blind-app" onClick={handleScreenClick}>
      <div className="status-text" style={{ color: statusColor }}>
        {statusText}
      </div>

      {/* ì •ë³´ ë²„íŠ¼ */}
      <button
        className="info-button"
        onClick={(e) =>
          handleButtonClick(
            e,
            'ì •ë³´ ë²„íŠ¼ì…ë‹ˆë‹¤. ë‘ ë²ˆ í´ë¦­í•˜ë©´ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ê¸°ëŠ¥ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.',
            () => speak(FEATURE_GUIDE)
          )
        }
      >
        â„¹ï¸
      </button>

      {/* ë¹„ë””ì˜¤ ì»¨í…Œì´ë„ˆ */}
      <div className="video-container" style={{ display: isRunning ? 'flex' : 'none' }}>
        <video
          ref={cameraPreviewRef}
          className="camera-preview"
          autoPlay
          playsInline
          muted
          onLoadedMetadata={handleVideoLoaded}
          style={{ display: isRunning ? 'block' : 'none' }}
        />
        <canvas
          ref={overlayCanvasRef}
          className="overlay-canvas"
          style={{ display: isRunning ? 'block' : 'none' }}
        />
        <canvas ref={cameraCanvasRef} style={{ display: 'none' }} />
      </div>

      {/* ì»¨íŠ¸ë¡¤ íŒ¨ë„ */}
      <div className="control-panel">
        <button
          className={`control-btn record-btn ${isRecording ? 'recording' : ''}`}
          onClick={(e) =>
            handleButtonClick(
              e,
              'ë…¹ìŒ ë²„íŠ¼ì…ë‹ˆë‹¤. ë‘ ë²ˆ í´ë¦­í•˜ë©´ ë…¹ìŒì„ ì‹œì‘í•˜ê±°ë‚˜ ì¤‘ì§€í•©ë‹ˆë‹¤.',
              toggleRecording
            )
          }
        >
          {isRecording ? 'ğŸ”´' : 'ğŸ¤'}
        </button>

        <button
          className="control-btn"
          onClick={(e) =>
            handleButtonClick(e, 'ìŒì†Œê±° ë²„íŠ¼ì…ë‹ˆë‹¤.', () => sendCommand('ì¡°ìš©íˆí•´'))
          }
        >
          ğŸ”‡
        </button>

        <button
          className="control-btn"
          onClick={(e) =>
            handleButtonClick(
              e,
              'ë§í•˜ê¸° ë²„íŠ¼ì…ë‹ˆë‹¤. í˜„ì¬ ìƒíƒœë¥¼ ìŒì„±ìœ¼ë¡œ ì•ˆë‚´í•©ë‹ˆë‹¤.',
              () => sendCommand('ë§í•´ì¤˜')
            )
          }
        >
          ğŸ“¢
        </button>

        <button
          className="control-btn exit-btn"
          onClick={(e) =>
            handleButtonClick(e, 'ì¢…ë£Œ ë²„íŠ¼ì…ë‹ˆë‹¤.', () => {
              sendCommand('ì¢…ë£Œí•´');
              setTimeout(() => window.location.href = '/', 1000);
            })
          }
        >
          ğŸ›‘
        </button>
      </div>
    </div>
  );
}

export default ObjectDetection;
